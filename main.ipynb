{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from ultralytics.utils.plotting import Annotator\n",
    "import os\n",
    "import time\n",
    "import torch, torch.nn as nn\n",
    "from torch.nn.utils import prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sorra\\projects\\mlproj\\gun-detection-system\\models\\v2\\best.pt\n",
      "Ultralytics YOLOv8.1.30 🚀 Python-3.12.2 torch-2.2.1+cpu CPU (AMD Ryzen 5 3550H with Radeon Vega Mobile Gfx)\n",
      "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\sorra\\projects\\mlproj\\merge_dataset\\valid\\labels.cache... 1607 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1607/1607 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 1, len(boxes) = 1821. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 101/101 [05:35<00:00,  3.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1607       1821      0.946       0.92      0.953       0.76\n",
      "Speed: 1.9ms preprocess, 195.9ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "version = 'v2'\n",
    "# weight = os.path.join('models', version, 'pruned.pt')\n",
    "weight = os.path.join('models', version, 'best.pt')\n",
    "weight_abspath = os.path.abspath(weight)\n",
    "\n",
    "print(weight_abspath)\n",
    "\n",
    "model = YOLO(weight, task='detect')\n",
    "# metrics = model.val(data=os.path.abspath('../merge_dataset/data.yaml'), plots=True, task='detect', conf=0.35)\n",
    "# model.export(format='onnx', int8=True, dynamic=True, simplify=True)\n",
    "# model.export(format='openvino', int8=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7595778086504898\n",
      "0.9526791491582957\n",
      "0.8636578261301457\n",
      "[    0.75958]\n"
     ]
    }
   ],
   "source": [
    "# print(metrics.box.map)    # map50-95 standard benchmark\n",
    "# print(metrics.box.map50)  # map50\n",
    "# print(metrics.box.map75)  # map75\n",
    "# print(metrics.box.maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sparsity(model):\n",
    "#     # Return global model sparsity\n",
    "#     a, b = 0, 0\n",
    "#     for p in model.parameters():\n",
    "#         a += p.numel()\n",
    "#         b += (p == 0).sum()\n",
    "#     return b / a\n",
    "\n",
    "# pruning_param = 0.8\n",
    "\n",
    "# for name, m in model.model.named_modules():\n",
    "#     if isinstance(m, nn.Conv2d) or isinstance(m, torch.nn.Linear):\n",
    "#         prune.l1_unstructured(m, name='weight', amount=pruning_param)  # prune\n",
    "#         prune.remove(m, 'weight')  # make permanent\n",
    "# print(f'Model pruned to {sparsity(model.model):.3g} global sparsity')\n",
    "\n",
    "# ckpt = {\n",
    "#     'model': model.model,\n",
    "#     'train_args': {},  # save as dict\n",
    "# }\n",
    "\n",
    "# torch.save(ckpt, os.path.abspath(os.path.join('models', version, 'pruned.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(0)\n",
    "# # cap = cv2.VideoCapture('sample.mp4')\n",
    "\n",
    "# # Initialize FPS calculation\n",
    "# prev_time = 0\n",
    "\n",
    "# while cap.isOpened():\n",
    "#     ret, frame = cap.read()\n",
    "\n",
    "#     current_time = time.time()\n",
    "\n",
    "#     results = model.predict(frame, conf=0.35, stream=True, vid_stride=5, stream_buffer=True)\n",
    "\n",
    "#     for result in results:\n",
    "\n",
    "#         # https://stackoverflow.com/questions/75324341/yolov8-get-predicted-bounding-box\n",
    "#         annotator = Annotator(frame)\n",
    "\n",
    "#         boxes = result.boxes\n",
    "#         conf_arr = boxes.conf.numpy()\n",
    "#         conf = 0\n",
    "#         for box in boxes:\n",
    "#             b = box.xyxy[0]\n",
    "#             c = box.cls\n",
    "            \n",
    "#             if len(conf_arr) > 0:\n",
    "#                 conf = conf_arr[0]\n",
    "#             annotator.box_label(b, model.names[int(c)]+\" \"+f'{conf:.2f}')\n",
    "    \n",
    "#     frame = annotator.result() \n",
    "\n",
    "#     # Calculate FPS\n",
    "#     fps = 1 / (current_time - prev_time)\n",
    "#     prev_time = current_time\n",
    "\n",
    "#     # Display FPS on top-left corner of the window\n",
    "#     cv2.putText(frame, f'FPS: {int(fps)}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "#     cv2.imshow('Gun detection', frame)\n",
    "\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
